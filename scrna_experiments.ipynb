{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training data\n",
    "\n",
    "import gdown\n",
    "\n",
    "url = \"https://drive.google.com/file/d/1VC9i5gvZAxCE-RkydXHdanXohY6OGO5P/view?usp=sharing\"\n",
    "output = \"data/scrna/schiebinger.npz\"\n",
    "gdown.download(url, output, quiet=False, fuzzy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.join(sys.path[0], \"code\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_models as models\n",
    "import pytorch_samplers as samplers\n",
    "import pytorch_losses as losses\n",
    "import pytorch_training as training\n",
    "import pytorch_utils as utils\n",
    "import sinkhorn_cnf as cnf\n",
    "import scrna_exper as scrna\n",
    "from geomloss import SamplesLoss\n",
    "from torchdiffeq import odeint as odeint\n",
    "\n",
    "import importlib\n",
    "import time\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm, colors\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "importlib.reload(models)\n",
    "importlib.reload(losses)\n",
    "importlib.reload(samplers)\n",
    "importlib.reload(training)\n",
    "importlib.reload(utils)\n",
    "importlib.reload(scrna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import WOT data\n",
    "\n",
    "data_file = \"data/scrna/schiebinger.npz\"\n",
    "data_dict = np.load(data_file, allow_pickle=True)\n",
    "\n",
    "all_data = data_dict[\"original_embedding\"]\n",
    "# Rescale the data by factor of 1e-3\n",
    "all_data *= 1e-3\n",
    "\n",
    "timestamps = data_dict[\"sample_labels\"]\n",
    "\n",
    "times = np.unique(timestamps)\n",
    "\n",
    "subsampled_data_list = []\n",
    "data_list = []\n",
    "# Generate training data by randomly selecting 500 observations per time point\n",
    "for t in list(times):\n",
    "    data_t = all_data[timestamps == t]\n",
    "    data_list.append(data_t)\n",
    "    np.random.shuffle(data_t) # shuffle rows of data_t\n",
    "    subsampled_data_t = data_t[:500] # keep only first 500 samples\n",
    "    subsampled_data_list.append(subsampled_data_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Learn metric tensor A(x) from Schiebinger data\n",
    "\n",
    "seed = 0\n",
    "n_samples = 500\n",
    "space_dims = 2\n",
    "scalar_hidden_dims = 128\n",
    "matrix_hidden_dims = 2048\n",
    "gp_strength_phi = 0\n",
    "gp_strength_R = 1e1\n",
    "fro_reg_strength = 5e2 # was 1e0\n",
    "identity_reg_strength = 0\n",
    "lr = 5e-3 # was 1e-2\n",
    "weight_decay = 1.5e-2\n",
    "n_epochs_phi = 100\n",
    "n_epochs_R = 5000 # was 1000\n",
    "R_model_type = \"singlelayer\"\n",
    "\n",
    "t0 = time.time()\n",
    "scrna_learnedA, phi_list, rho_0_list, rho_1_list = training.twostep_train_wot_model(subsampled_data_list,\n",
    "                                                                                    n_samples,\n",
    "                                                                                    scalar_hidden_dims,\n",
    "                                                                                    matrix_hidden_dims,\n",
    "                                                                                    fro_reg_strength,\n",
    "                                                                                    identity_reg_strength,\n",
    "                                                                                    gp_strength_phi,\n",
    "                                                                                    gp_strength_R,\n",
    "                                                                                    lr,\n",
    "                                                                                    weight_decay,\n",
    "                                                                                    n_epochs_phi,\n",
    "                                                                                    n_epochs_R,\n",
    "                                                                                    seed,\n",
    "                                                                                    R_model_type\n",
    "                                                                                   )\n",
    "\n",
    "t1 = time.time()\n",
    "print('elapsed time: ' + str(t1-t0) + ' s.')\n",
    "\n",
    "# Plot eigenvectors of metric\n",
    "plt.figure(figsize=(20,20))\n",
    "# Eigs plot params\n",
    "x_lims = (-15,15)\n",
    "y_lims = (-10,15)\n",
    "n = 50\n",
    "utils.eigs_quiver(scrna_learnedA, n, x_lims, y_lims)\n",
    "for t in range(len(times)):\n",
    "    label = \"t = \" + str(times[t])\n",
    "    plt.scatter(subsampled_data_list[t][:,0], subsampled_data_list[t][:,1], label=label, alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "\n",
    "scrna_learned_path = \"trained_models/scrna_learned_params_v3.pt\"\n",
    "torch.save(scrna_learnedA.state_dict(), scrna_learned_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load pretrained model\n",
    "\n",
    "space_dims = 2\n",
    "matrix_hidden_dims = 2048\n",
    "A_fname = \"trained_models/scrna_learned_params_v3.pt\" # was 'scrna_pretrained_params.pt'\n",
    "scrna_learnedA = models.PSDMatrix(space_dims, matrix_hidden_dims).to(device)\n",
    "scrna_learnedA.load_state_dict(torch.load(A_fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate list of samplers for all time points\n",
    "\n",
    "rho_list = samplers.generate_all_eb_samplers(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run experiments without A\n",
    "\n",
    "k_vals = [2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19]\n",
    "A_model = scrna_learnedA\n",
    "for k in k_vals:\n",
    "    json_fname = \"results/scrna_experiments/k\" + str(k) + \"_noA.json\"\n",
    "    use_A = False\n",
    "    W1_vals = scrna.run_experiment(rho_list, json_fname, k, A_model, use_A)\n",
    "    json_fname_final_tps = \"results/scrna_experiments/k\" + str(k) + \"_noA_final_tps.json\"\n",
    "    W1_vals_final_tps = scrna.run_final_tp_experiment(rho_list, json_fname_final_tps, k, A_model, use_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define A_model that always returns the identity matrix\n",
    "\n",
    "class IdentityMatrix(nn.Module):\n",
    "    \"\"\"Just returns the identiy matrix.\"\"\"\n",
    "\n",
    "    def __init__(self, space_dims):\n",
    "        super(IdentityMatrix, self).__init__()\n",
    "        self.d = space_dims\n",
    "    def forward(self, x):\n",
    "        return torch.eye(space_dims, device=device).repeat(x.shape[0], 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_model = IdentityMatrix(2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run experiments with A\n",
    "\n",
    "k_vals = [2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19]\n",
    "A_model = scrna_learnedA\n",
    "for k in k_vals:\n",
    "    json_fname = \"results/scrna_experiments/k\" + str(k) + \"_withA_lambd_1em1.json\"\n",
    "    use_A = True\n",
    "    W1_vals = scrna.run_experiment(rho_list, json_fname, k, A_model, use_A)\n",
    "    json_fname_final_tps = \"results/scrna_experiments/k\" + str(k) + \"_withA_lambd_1em1_final_tps.json\"\n",
    "    W1_vals_final_tps = scrna.run_final_tp_experiment(rho_list, json_fname_final_tps, k, A_model, use_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run experiments with identity matrix as A\n",
    "\n",
    "k_vals = [2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19]\n",
    "A_model = id_model\n",
    "for k in k_vals:\n",
    "    json_fname = \"results/scrna_experiments/k\" + str(k) + \"_withIdentityA_lambd_1em1.json\"\n",
    "    use_A = True\n",
    "    W1_vals = scrna.run_experiment(rho_list, json_fname, k, A_model, use_A)\n",
    "    json_fname_final_tps = \"results/scrna_experiments/k\" + str(k) + \"_withIdentityA_lambd_1em1_final_tps.json\"\n",
    "    W1_vals_final_tps = scrna.run_final_tp_experiment(rho_list, json_fname_final_tps, k, A_model, use_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELLS BELOW ARE FOR GENERATING PLOTS FROM EXPERIMENTAL RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute W1 vals across multiple runs with metric tensor\n",
    "\n",
    "k_vals = [2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19]\n",
    "withA_mean_list = []\n",
    "withA_std_list = []\n",
    "use_A = True\n",
    "n_runs = 10\n",
    "for k in k_vals:\n",
    "    mean, std = scrna.compute_multiple_runs(rho_list, k, use_A, n_runs)\n",
    "    withA_mean_list.append(mean)\n",
    "    withA_std_list.append(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "withA_means = torch.tensor(withA_mean_list)\n",
    "noA_means = torch.tensor(noA_mean_list)\n",
    "torch.mean((withA_means[10:] - noA_means[10:])/noA_means[10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute W1 vals across multiple runs without metric tensor\n",
    "\n",
    "k_vals = [2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19]\n",
    "noA_mean_list = []\n",
    "noA_std_list = []\n",
    "use_A = False\n",
    "n_runs = 10\n",
    "for k in k_vals:\n",
    "    mean, std = scrna.compute_multiple_runs(rho_list, k, use_A, n_runs)\n",
    "    noA_mean_list.append(mean)\n",
    "    noA_std_list.append(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute W1 vals across multiple runs with identity metric tensor\n",
    "# Need to modify the code for compute_multiple_runs to accomplish this\n",
    "\n",
    "k_vals = [2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19]\n",
    "IdentityA_mean_list = []\n",
    "IdentityA_std_list = []\n",
    "use_A = True\n",
    "n_runs = 10\n",
    "for k in k_vals:\n",
    "    mean, std = scrna.compute_multiple_runs(rho_list, k, use_A, n_runs)\n",
    "    IdentityA_mean_list.append(mean)\n",
    "    IdentityA_std_list.append(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate scRNA W1 comparison (with vs without learned metric tensor)\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.errorbar(k_vals, noA_mean_list, yerr = noA_std_list, label=\"Without A\", linewidth=5, ecolor=\"black\")\n",
    "plt.errorbar(k_vals, withA_mean_list, yerr = withA_std_list, label=\"Learned A\", linewidth=5, ecolor=\"black\")\n",
    "plt.errorbar(k_vals, IdentityA_mean_list, yerr = IdentityA_std_list, label=\"A = Id\", linewidth=5, ecolor=\"black\")\n",
    "plt.xlabel(\"k\", size=30)\n",
    "plt.xticks(k_vals[::2])\n",
    "plt.ylabel(\"EMD\", size=30)\n",
    "plt.tick_params(axis='both', which='major', labelsize=30)\n",
    "plt.legend(fontsize=30)\n",
    "# Save figure\n",
    "plt.savefig(\"results/scrna_emd_plot_with_identity.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate scRNA trajectory inference plots\n",
    "\n",
    "fig = plt.figure(figsize=(30,20))\n",
    "ax1 = fig.add_subplot(2,3,1)\n",
    "ax2 = fig.add_subplot(2,3,2)\n",
    "ax4 = fig.add_subplot(2,3,4)\n",
    "ax5 = fig.add_subplot(2,3,5)\n",
    "ax3 = fig.add_subplot(2,3,3)\n",
    "ax6 = fig.add_subplot(2,3,6)\n",
    "\n",
    "# Do k=3 for case where A doesn't help much\n",
    "\n",
    "k = 3\n",
    "scrna.visualize_advected_samples_all_times(ax1, rho_list, k, use_A=False)\n",
    "scrna.visualize_advected_samples_all_times(ax2, rho_list, k, use_A=True)\n",
    "\n",
    "# Do k=15 for case where A helps a lot\n",
    "\n",
    "k = 15\n",
    "scrna.visualize_advected_samples_all_times(ax4, rho_list, k, use_A=False)\n",
    "scrna.visualize_advected_samples_all_times(ax5, rho_list, k, use_A=True)\n",
    "\n",
    "# Plot ground truth\n",
    "\n",
    "norm = colors.Normalize(vmin=0, vmax=len(data_list))\n",
    "cmap = cm.viridis\n",
    "for t in range(len(data_list)):\n",
    "    data = data_list[t][:1000]\n",
    "    ax3.scatter(data[:,0], data[:,1], color=cmap(norm(t)), s=0.1)\n",
    "    ax6.scatter(data[:,0], data[:,1], color=cmap(norm(t)), s=0.1)\n",
    "\n",
    "ax1.set_title(\"Baseline\", fontsize=\"xx-large\", fontweight=\"bold\")\n",
    "ax2.set_title(\"Ours\", fontsize=\"xx-large\", fontweight=\"bold\")\n",
    "ax3.set_title(\"Ground truth\", fontsize=\"xx-large\", fontweight=\"bold\")\n",
    "\n",
    "# Save figure\n",
    "plt.savefig(\"results/scrna_traj_plots.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:labb]",
   "language": "python",
   "name": "conda-env-labb-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
